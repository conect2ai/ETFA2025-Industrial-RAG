{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÑ Text Extraction from PDFs\n",
    "\n",
    "This notebook automates the extraction of textual content from PDF files.  \n",
    "The main steps include:\n",
    "\n",
    "- Filtering and organizing input files.\n",
    "- Processing each document to extract its textual data.\n",
    "- Applying basic preprocessing and cleaning techniques.\n",
    "- Saving the extracted and cleaned text for future analysis.\n",
    "\n",
    "The goal is to create a structured and organized dataset of texts extracted from technical or academic PDF documents.\n",
    "\n",
    "> üõ†Ô∏è This workflow is particularly useful for preparing data for Natural Language Processing (NLP) tasks, document classification, and information retrieval projects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install marker-pdf\n",
    "%pip install marker-pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FUNPEC\\anaconda3\\envs\\tmp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
      "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
      "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Copia di GSD-Spec_2122_V51_Jul08.pdf',\n",
       " 'Copia di iec61158-1{ed1.0}b.pdf',\n",
       " 'Copia di iec61158-2{ed6.0}b.pdf',\n",
       " 'Copia di iec61158-4-3{ed3.0}b.pdf',\n",
       " 'Copia di iec61158-5-3{ed3.0}b.pdf',\n",
       " 'Copia di iec61158-6-3{ed3.0}b.pdf',\n",
       " 'Copia di iec61784-1{ed4.0}b.pdf',\n",
       " 'Copia di iec61784-3-3{ed2.0}en.pdf',\n",
       " 'Copia di iec61784-5-3{ed3.0}b.pdf',\n",
       " 'Copia di PROFIdrive_3172_V42_Oct15.pdf',\n",
       " 'Copia di Profile-PA-Devices_3042_V402MU1_Mar22.pdf',\n",
       " 'Copia di PROFIsafe-Profile_3192b_V24_Mar07.pdf',\n",
       " 'iec61158-3-3{ed2.0}b.pdf',\n",
       " 'Perguntas - Desenvolvedores.docx']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.output import text_from_rendered\n",
    "\n",
    "input_folder = \"pdfs_developers\"\n",
    "output_folder = \"Processed_Files_Developers\"\n",
    "\n",
    "# Create the input folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize the PdfConverter with the model dictionary\n",
    "converter = PdfConverter(\n",
    "    artifact_dict=create_model_dict(),\n",
    ")\n",
    "\n",
    "file_names = os.listdir(input_folder)\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Copia di GSD-Spec_2122_V51_Jul08.pdf',\n",
       " 'Copia di iec61158-1{ed1.0}b.pdf',\n",
       " 'Copia di iec61158-2{ed6.0}b.pdf',\n",
       " 'Copia di iec61158-4-3{ed3.0}b.pdf',\n",
       " 'Copia di iec61158-5-3{ed3.0}b.pdf',\n",
       " 'Copia di iec61158-6-3{ed3.0}b.pdf',\n",
       " 'Copia di iec61784-1{ed4.0}b.pdf',\n",
       " 'Copia di iec61784-3-3{ed2.0}en.pdf',\n",
       " 'Copia di iec61784-5-3{ed3.0}b.pdf',\n",
       " 'Copia di PROFIdrive_3172_V42_Oct15.pdf',\n",
       " 'Copia di Profile-PA-Devices_3042_V402MU1_Mar22.pdf',\n",
       " 'Copia di PROFIsafe-Profile_3192b_V24_Mar07.pdf',\n",
       " 'iec61158-3-3{ed2.0}b.pdf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only pdf files\n",
    "file_names = [file for file in file_names if file.endswith(\".pdf\")]\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:08<00:00,  1.81it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:00<00:00, 125.39it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "c:\\Users\\FUNPEC\\anaconda3\\envs\\tmp\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] O sistema n√£o pode encontrar o arquivo especificado\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\FUNPEC\\anaconda3\\envs\\tmp\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\FUNPEC\\anaconda3\\envs\\tmp\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\FUNPEC\\anaconda3\\envs\\tmp\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\FUNPEC\\anaconda3\\envs\\tmp\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:06<00:00,  1.05it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:14<00:00,  1.82it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 127.67it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Recognizing Text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.74it/s]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:05<00:00,  1.56it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 169/169 [01:25<00:00,  1.98it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253/253 [00:02<00:00, 117.51it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Texify inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:12<00:00,  3.00s/it]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 768). Running this sequence through the model will result in indexing errors\n",
      "Detecting bboxes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.16it/s]\n",
      "Recognizing Text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 141/141 [01:12<00:00,  1.94it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [00:26<00:00,  2.23it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [00:00<00:00, 108.18it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Texify inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:40<00:00,  2.37s/it]\n",
      "Detecting bboxes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.51it/s]\n",
      "Recognizing Text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54/54 [00:33<00:00,  1.61it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [01:30<00:00,  1.67it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [00:01<00:00, 124.63it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.68it/s]\n",
      "Recognizing Text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 149/149 [01:42<00:00,  1.45it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 124/124 [00:58<00:00,  2.11it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [00:01<00:00, 114.65it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Texify inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.24s/it]\n",
      "Detecting bboxes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.00it/s]\n",
      "Recognizing Text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.20it/s]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 148/148 [01:21<00:00,  1.82it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [00:53<00:00,  2.26it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:01<00:00, 116.35it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Texify inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Detecting bboxes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.58it/s]\n",
      "Recognizing Text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175/175 [01:55<00:00,  1.51it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [00:10<00:00,  2.01it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:00<00:00, 129.58it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Texify inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.38it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:09<00:00,  1.61it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:21<00:00,  1.81it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 58/58 [00:00<00:00, 137.61it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.14it/s]\n",
      "Recognizing Text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:20<00:00,  1.59it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [00:23<00:00,  2.10it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 73/73 [00:00<00:00, 120.75it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Texify inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.77it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:32<00:00,  1.71it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:21<00:00,  2.24it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71/71 [00:00<00:00, 135.08it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Texify inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [00:46<00:00,  1.48it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:09<00:00,  2.01it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 142.33it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Texify inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:08<00:00,  1.70it/s]\n",
      "Recognizing layout: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:13<00:00,  1.89it/s]\n",
      "Running OCR Error Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37/37 [00:00<00:00, 136.76it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:17<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Process each PDF file\n",
    "for filename in file_names:\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_name = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Create a folder for the output files\n",
    "        file_output_folder = os.path.join(output_folder, output_name)\n",
    "        os.makedirs(file_output_folder, exist_ok=True)\n",
    "        \n",
    "        # Convert PDF\n",
    "        rendered = converter(input_path)\n",
    "        text, _, images = text_from_rendered(rendered)\n",
    "        \n",
    "        # Save the text to a markdown file\n",
    "        with open(os.path.join(file_output_folder, f\"{output_name}.md\"), \"w\") as md_file:\n",
    "            md_file.write(text)\n",
    "        \n",
    "        # Save the images to the output folder\n",
    "        for name, image in images.items():\n",
    "            image_path = os.path.join(file_output_folder, name)\n",
    "            image.save(image_path)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_introduction_to_end(markdown_file, output_file=\"introduction_to_end.md\"):\n",
    "    with open(markdown_file, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # List of possible titles indicating the start of the desired section\n",
    "    possible_titles = [\n",
    "        r\"Introduction\", \n",
    "        r\"General\", \n",
    "        r\"Mapping Model\", \n",
    "        r\"Guidelines for implementers and users\", \n",
    "        r\"INDUSTRIAL COMMUNICATION NETWORKS ‚Äì FIELDBUS SPECIFICATIONS ‚Äì\",\n",
    "        r\"INDUSTRIAL COMMUNICATION NETWORKS ‚Äì PROFILES ‚Äì\",\n",
    "        r\"IO-Link master integration strategy \\(system description\\)\",\n",
    "        r\"Concepts\"\n",
    "    ]\n",
    "\n",
    "    # Create regex patterns to match different formats\n",
    "    title_patterns = [\n",
    "        rf\"^#+\\s*<.*?>?\\s*\\*\\*\\d*\\.?\\s*({title})\\*\\*\" for title in possible_titles  # With ID and bold\n",
    "    ] + [\n",
    "        rf\"^#+\\s*\\*\\*\\d*\\.?\\s*({title})\\*\\*\" for title in possible_titles  # Bold only\n",
    "    ] + [\n",
    "        rf\"^#+\\s*({title})\" for title in possible_titles  # Plain text only\n",
    "    ]\n",
    "\n",
    "    compiled_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in title_patterns]\n",
    "\n",
    "    start_index = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if any(pattern.search(line) for pattern in compiled_patterns):\n",
    "            start_index = i\n",
    "            break\n",
    "\n",
    "    if start_index is None:\n",
    "        print(\"Introduction section (or equivalent) not found.\")\n",
    "        return\n",
    "\n",
    "    # Extract everything from the found section to the end of the document\n",
    "    intro_to_end = lines[start_index:]\n",
    "\n",
    "    # Save the extracted content into a new file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        out_file.writelines(intro_to_end)\n",
    "\n",
    "    print(f\"Extracted content saved to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction section (or equivalent) not found.\n",
      "Extracted content saved to 'Processed_Files_Introduction_to_End/Copia di iec61158-1{ed1.0}b.md'.\n",
      "Extracted content saved to 'Processed_Files_Introduction_to_End/Copia di iec61158-2{ed6.0}b.md'.\n",
      "Extracted content saved to 'Processed_Files_Introduction_to_End/Copia di iec61158-4-3{ed3.0}b.md'.\n",
      "Extracted content saved to 'Processed_Files_Introduction_to_End/Copia di iec61158-5-3{ed3.0}b.md'.\n",
      "Extracted content saved to 'Processed_Files_Introduction_to_End/Copia di iec61158-6-3{ed3.0}b.md'.\n",
      "Extracted content saved to 'Processed_Files_Introduction_to_End/Copia di iec61784-1{ed4.0}b.md'.\n",
      "Extracted content saved to 'Processed_Files_Introduction_to_End/Copia di iec61784-3-3{ed2.0}en.md'.\n",
      "Extracted content saved to 'Processed_Files_Introduction_to_End/Copia di iec61784-5-3{ed3.0}b.md'.\n",
      "Introduction section (or equivalent) not found.\n",
      "Introduction section (or equivalent) not found.\n",
      "Extracted content saved to 'Processed_Files_Introduction_to_End/Copia di PROFIsafe-Profile_3192b_V24_Mar07.md'.\n",
      "Extracted content saved to 'Processed_Files_Introduction_to_End/iec61158-3-3{ed2.0}b.md'.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"Processed_Files_Introduction_to_End\", exist_ok=True)\n",
    "\n",
    "# Execute the extraction for each markdown file in the output folder\n",
    "for folders in os.listdir(f\"{output_folder}\"):\n",
    "    for file in os.listdir(f\"{output_folder}/{folders}\"):\n",
    "        if file.endswith(\".md\"):\n",
    "            extract_introduction_to_end(f\"{output_folder}/{folders}/{file}\", f\"Processed_Files_Introduction_to_End/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
